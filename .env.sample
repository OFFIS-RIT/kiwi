# App
DEBUG=false
PORT=8080
MASTER_API_KEY=<api_key>
MASTER_USER_ID=<user_id (int)>
MASTER_USER_ROLE=admin

# Frontend
NEXT_PUBLIC_API_URL=http://server:8080
# Local
# NEXT_PUBLIC_API_URL=http://localhost:8080/api

# Database
DATABASE_URL=postgresql://kiwi:kiwi@db:5432/kiwi?sslmode=disable

# Auth
AUTH_SECRET=<random_secret_min_32_chars>
AUTH_URL=http://auth:4321/auth
# AUTH_URL=https://yourdomain.com/auth -- For production

# Keycloak
JWKS_URL=http://keycloak:7080/realms/master/protocol/openid-connect/certs

# S3
AWS_REGION=eu-central-1
AWS_ENDPOINT=http://rustfs:9000
# AWS_PUBLIC_ENDPOINT=http://<url>/s3 -- For production with nginx
AWS_PUBLIC_ENDPOINT=http://localhost:9000
AWS_ACCESS_KEY=kiwi
AWS_SECRET_KEY=kiwi
AWS_BUCKET=kiwi

# AI Adapter
# When using adapter ollama only AI_CHAT_URL is used for all models
AI_ADAPTER=openai
# AI_ADAPTER=ollama
AI_PARALLEL_REQ=15

# Note: You can use any compatible API by setting a custom URL:
# - OpenRouter: https://openrouter.ai/api/v1
# - Local vLLM/llama.cpp: http://localhost:8000/v1
# - Ollama: http://ollama:11434

# Chat
AI_CHAT_KEY=<api_key>
# Leave URL commented to use default OpenAI endpoint
# AI_CHAT_URL=http://ollama:11434
AI_CHAT_DESCRIBE_MODEL=gpt-4o
AI_CHAT_EXTRACT_MODEL=gpt-4o

AI_IMAGE_KEY=<api_key>
# Leave URL commented to use default OpenAI endpoint
# AI_IMAGE_URL=http://ollama:11434
AI_IMAGE_MODEL=gpt-4o

# Embedding
AI_EMBED_KEY=<api_key>
# Leave URL commented to use default OpenAI endpoint
# AI_EMBED_URL=http://ollama:11434
AI_EMBED_MODEL=text-embedding-3-small
AI_EMBED_DIM=4096

# RabbitMQ
RABBITMQ_USER=kiwi
RABBITMQ_PASSWORD=kiwi
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
